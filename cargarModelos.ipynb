{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YrkJxwLT-mgFbaQLJGMfVLFhtObz31ns",
      "authorship_tag": "ABX9TyMIHsCyJOIol2h+bLKWNCY2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guiniel/Pasantia-IA-CNTM/blob/main/cargarModelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instalamos los mismos paquetes de antes**"
      ],
      "metadata": {
        "id": "nZplhioRj0IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyyaml h5py\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "mhsK1UqXE7iT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d4c9b8-9956-4d9a-acb8-a898f243b0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-uqk9nust\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-uqk9nust\n",
            "  Resolved https://github.com/tensorflow/docs to commit b64768499123da8b2253a534277d62e20de3ec73\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor (from tensorflow-docs==2024.2.5.73858)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (3.1.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (5.10.2)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2024.2.5.73858) (2.1.5)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (0.18.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==2024.2.5.73858) (4.2.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-2024.2.5.73858-py3-none-any.whl size=182442 sha256=8f136dc5199095bc9fe275fda0a90d6cd228bf104a4ac2ac661b9c562fba0c5f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9iygcoy1/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: astor, tensorflow-docs\n",
            "Successfully installed astor-0.8.1 tensorflow-docs-2024.2.5.73858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importamos los paquetes a usar**"
      ],
      "metadata": {
        "id": "NmFKHzOuj-N8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quX-B4DhsFHv"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "np.set_printoptions(precision=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cargamos el dataset de ejemplo para realizar mis aproximaciones**"
      ],
      "metadata": {
        "id": "yR1kqpz-kDwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pd = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datasets/Evaluacion.csv\")\n"
      ],
      "metadata": {
        "id": "Zg0gKB1OwgOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Guardamos las columnas que no necesitamos y nos quedamos con las necesarias para poder hacer la prediccion**"
      ],
      "metadata": {
        "id": "J7kqIJOhka7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Task_ID','Task_Name','Status', 'Start_Date','Due_Date','Time_Estimate','Time_Logged','Lists','Año','Q']\n",
        "saved_columns = data_pd[columns]\n",
        "data_pd = data_pd.drop(['Task_ID'], axis=1).drop(['Task_Name'], axis=1).drop(['Status'], axis=1).drop(['Start_Date'], axis=1).drop(['Due_Date'], axis=1).drop(['Time_Estimate'], axis=1).drop(['Time_Logged'], axis = 1).drop(['Año'],axis=1).drop(['Lists'], axis=1).drop(['Q'], axis=1)\n"
      ],
      "metadata": {
        "id": "mE5AS8h71IrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Aqui hay funciones para par de metricas y para cargar el modelo**"
      ],
      "metadata": {
        "id": "hSazxMfpkp5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_modelo(ruta_archivo):\n",
        "    nombre_archivo, extension = os.path.splitext(ruta_archivo)\n",
        "    if extension == '.pkl':\n",
        "        return joblib.load(ruta_archivo)\n",
        "    elif extension == '.h5':\n",
        "        return keras.models.load_model(ruta_archivo, custom_objects={'median_relative_error': median_relative_error, 'r_squared': r_squared})\n",
        "    else:\n",
        "        raise ValueError(\"Extensión de archivo no compatible.\")\n",
        "def median_relative_error(y_true, y_pred):\n",
        "    error = tf.math.abs(y_true - y_pred) / tf.maximum(tf.math.abs(y_true), 1e-7)\n",
        "    return tf.keras.backend.mean(error)\n",
        "\n",
        "def r_squared(y_true, y_pred):\n",
        "    SS_res =  tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "    SS_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
        "    return 1 - SS_res/(SS_tot + tf.keras.backend.epsilon())\n"
      ],
      "metadata": {
        "id": "7rN7BmZeGIGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Aqui cargamos el modelo, realizamos las predicciones para el conjunto de datos cargados y lo exportamos con el mismo formato con el que entra**\n",
        "\n",
        "### **Se puede elegir entre 6 modelos diferentes y el excel generado se crea en la carpeta de trabajo con el nombre del modelo**"
      ],
      "metadata": {
        "id": "w37cN3zKkzw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_directory = '/content/drive/MyDrive/Colab Notebooks/modelos'\n",
        "model_files = os.listdir(model_directory)\n",
        "\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    print(\"Modelos disponibles:\")\n",
        "    for i, model_file in enumerate(model_files):\n",
        "        print(f\"{i+1}. {model_file}\")\n",
        "\n",
        "    print(\"0. Salir\")\n",
        "\n",
        "    # Pide al usuario que seleccione un modelo o salir\n",
        "    selected_option = input(\"Por favor, selecciona un modelo o ingresa '0' para salir: \")\n",
        "\n",
        "    if selected_option == '0':\n",
        "        print(\"Saliendo del programa...\")\n",
        "        break  # Sale del bucle si el usuario elige salir\n",
        "\n",
        "    try:\n",
        "        selected_model_index = int(selected_option) - 1\n",
        "\n",
        "        #Verifica si la selección está dentro del rango de modelos disponibles\n",
        "        if selected_model_index < 0 or selected_model_index >= len(model_files):\n",
        "            print(\"Por favor, selecciona una opción válida.\")\n",
        "            continue\n",
        "\n",
        "        selected_model_path = os.path.join(model_directory, model_files[selected_model_index])\n",
        "        print(f\"Cargando modelo desde {selected_model_path}...\")\n",
        "\n",
        "        # Cargamos el modelo\n",
        "        model = cargar_modelo(selected_model_path)\n",
        "\n",
        "        result = model.predict(data_pd).flatten()\n",
        "\n",
        "        # Juntamos la tabla nuevamente\n",
        "        table = pd.concat([saved_columns, data_pd], axis=1)\n",
        "\n",
        "        print(table)\n",
        "        # Ordenamos los valores\n",
        "\n",
        "        table = table[['Task_ID', 'Task_Name','Assignee', 'Status', 'Start_Date', 'Due_Date', 'Esfuerzo_Aproximado', 'Time_Estimate', 'Time_Logged','Año','Q','Mes','Lists']]\n",
        "        # Agregamos los valores de prediccion\n",
        "        table['Time_Estimate'] = result\n",
        "\n",
        "        model_name = os.path.splitext(model_files[selected_model_index])[0]\n",
        "        excel_filename = f\"prediccion_{model_name}.xlsx\"\n",
        "\n",
        "        # Exportamos a excel\n",
        "        table.to_excel(excel_filename, index = False)\n",
        "    except ValueError:\n",
        "        print(\"Por favor, ingresa un número válido.\")\n",
        "        input(\"Pulsa cualquier tecla para continuar...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uMGbNaV547f",
        "outputId": "c4ae3a6e-ab38-4dac-9bd7-b7c328dd9fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos disponibles:\n",
            "1. knr_trained.pkl\n",
            "2. gbr_trained.pkl\n",
            "3. rfr_trained.pkl\n",
            "4. nn2_trained.h5\n",
            "5. nn3_trained.h5\n",
            "6. nn5_trained.h5\n",
            "7. .ipynb_checkpoints\n",
            "0. Salir\n",
            "Por favor, selecciona un modelo o ingresa '0' para salir: 0\n",
            "Saliendo del programa...\n"
          ]
        }
      ]
    }
  ]
}